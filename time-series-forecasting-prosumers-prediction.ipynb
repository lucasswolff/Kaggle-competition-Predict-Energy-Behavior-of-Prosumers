{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e252b0",
   "metadata": {
    "papermill": {
     "duration": 0.010625,
     "end_time": "2024-01-30T22:42:18.308098",
     "exception": false,
     "start_time": "2024-01-30T22:42:18.297473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Baseline taken [Enefit Generic Notebook](https://www.kaggle.com/code/greysky/enefit-generic-notebook) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cafcaade",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-30T22:42:18.329319Z",
     "iopub.status.busy": "2024-01-30T22:42:18.329047Z",
     "iopub.status.idle": "2024-01-30T22:42:24.518991Z",
     "shell.execute_reply": "2024-01-30T22:42:24.518032Z"
    },
    "papermill": {
     "duration": 6.202846,
     "end_time": "2024-01-30T22:42:24.521186",
     "exception": false,
     "start_time": "2024-01-30T22:42:18.318340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "import holidays\n",
    "import ephem\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor, StackingRegressor, BaggingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e539a6d4",
   "metadata": {
    "papermill": {
     "duration": 0.010019,
     "end_time": "2024-01-30T22:42:24.541729",
     "exception": false,
     "start_time": "2024-01-30T22:42:24.531710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a86b43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:42:24.563038Z",
     "iopub.status.busy": "2024-01-30T22:42:24.562720Z",
     "iopub.status.idle": "2024-01-30T22:42:24.569853Z",
     "shell.execute_reply": "2024-01-30T22:42:24.569015Z"
    },
    "papermill": {
     "duration": 0.019854,
     "end_time": "2024-01-30T22:42:24.571749",
     "exception": false,
     "start_time": "2024-01-30T22:42:24.551895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = \"/kaggle/input/predict-energy-behavior-of-prosumers\"\n",
    "\n",
    "data_cols = ['target', 'county', 'is_business', 'product_type', 'is_consumption', 'datetime', 'row_id']\n",
    "client_cols = ['product_type', 'county', 'eic_count', 'installed_capacity', 'is_business', 'date']\n",
    "gas_prices_cols = ['forecast_date', 'lowest_price_per_mwh', 'highest_price_per_mwh']\n",
    "electricity_prices_cols = ['forecast_date', 'euros_per_mwh']\n",
    "forecast_weather_cols = ['latitude', 'longitude', 'hours_ahead', 'temperature', 'dewpoint', 'cloudcover_high', 'cloudcover_low', 'cloudcover_mid', 'cloudcover_total', '10_metre_u_wind_component', '10_metre_v_wind_component', 'forecast_datetime', 'direct_solar_radiation', 'surface_solar_radiation_downwards', 'snowfall', 'total_precipitation']\n",
    "historical_weather_cols = ['datetime', 'temperature', 'dewpoint', 'rain', 'snowfall', 'surface_pressure','cloudcover_total','cloudcover_low','cloudcover_mid','cloudcover_high','windspeed_10m','winddirection_10m','shortwave_radiation','direct_solar_radiation','diffuse_radiation','latitude','longitude']\n",
    "location_cols = ['longitude', 'latitude', 'county']\n",
    "target_cols = ['target', 'county', 'is_business', 'product_type', 'is_consumption', 'datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f0ae4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:42:24.592918Z",
     "iopub.status.busy": "2024-01-30T22:42:24.592640Z",
     "iopub.status.idle": "2024-01-30T22:42:29.062193Z",
     "shell.execute_reply": "2024-01-30T22:42:29.061158Z"
    },
    "papermill": {
     "duration": 4.482724,
     "end_time": "2024-01-30T22:42:29.064549",
     "exception": false,
     "start_time": "2024-01-30T22:42:24.581825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_data = pl.read_csv(os.path.join(root, \"train.csv\"), columns=data_cols, try_parse_dates=True)\n",
    "df_client = pl.read_csv(os.path.join(root, \"client.csv\"), columns=client_cols, try_parse_dates=True)\n",
    "df_gas_prices = pl.read_csv(os.path.join(root, \"gas_prices.csv\"), columns=gas_prices_cols, try_parse_dates=True)\n",
    "df_electricity_prices = pl.read_csv(os.path.join(root, \"electricity_prices.csv\"), columns=electricity_prices_cols, try_parse_dates=True)\n",
    "df_forecast_weather = pl.read_csv(os.path.join(root, \"forecast_weather.csv\"), columns=forecast_weather_cols, try_parse_dates=True)\n",
    "df_historical_weather = pl.read_csv(os.path.join(root, \"historical_weather.csv\"), columns=historical_weather_cols, try_parse_dates=True)\n",
    "df_weather_station_to_county_mapping = pl.read_csv(os.path.join(root, \"weather_station_to_county_mapping.csv\"), columns=location_cols, try_parse_dates=True)\n",
    "df_target = df_data.select(target_cols)\n",
    "\n",
    "schema_data = df_data.schema\n",
    "schema_client = df_client.schema\n",
    "schema_gas  = df_gas_prices.schema\n",
    "schema_electricity = df_electricity_prices.schema\n",
    "schema_forecast = df_forecast_weather.schema\n",
    "schema_historical = df_historical_weather.schema\n",
    "schema_target = df_target.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a43535fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:42:29.086417Z",
     "iopub.status.busy": "2024-01-30T22:42:29.086127Z",
     "iopub.status.idle": "2024-01-30T22:42:29.112043Z",
     "shell.execute_reply": "2024-01-30T22:42:29.111332Z"
    },
    "papermill": {
     "duration": 0.038788,
     "end_time": "2024-01-30T22:42:29.113901",
     "exception": false,
     "start_time": "2024-01-30T22:42:29.075113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estonian_holidays = holidays.country_holidays('EE', years=range(2020, 2026))\n",
    "estonian_holidays = list(estonian_holidays.keys())\n",
    "df_estonian_holidays = pd.DataFrame(estonian_holidays, columns=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e17b8e0",
   "metadata": {
    "papermill": {
     "duration": 0.009924,
     "end_time": "2024-01-30T22:42:29.133946",
     "exception": false,
     "start_time": "2024-01-30T22:42:29.124022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utilities\n",
    "Functions to be used as aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb2d4987",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:42:29.155508Z",
     "iopub.status.busy": "2024-01-30T22:42:29.155011Z",
     "iopub.status.idle": "2024-01-30T22:42:29.160880Z",
     "shell.execute_reply": "2024-01-30T22:42:29.160093Z"
    },
    "papermill": {
     "duration": 0.018527,
     "end_time": "2024-01-30T22:42:29.162722",
     "exception": false,
     "start_time": "2024-01-30T22:42:29.144195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extend_columns_fill(columns_fill, df):\n",
    "    \n",
    "    columns_substrings = ['temperature', 'dewpoint', 'cloudcover_high', 'cloudcover_low', 'cloudcover_mid',\n",
    "                        'cloudcover_total', '10_metre_u_wind_component', '10_metre_v_wind_component', 'direct_solar_radiation',\n",
    "                        'surface_solar_radiation_downwards', 'snowfall', 'total_precipitation_', 'temperature',\n",
    "                         'surface_pressure', 'windspeed', 'winddirection', 'shortwave_radiation', 'diffuse_radiation', \n",
    "                         'rain', 'surface_pressure', 'windspeed']\n",
    "    \n",
    "    all_columns = df.columns.tolist()\n",
    "    selected_columns = [name for name in all_columns if any(substring in name for substring in columns_substrings)]\n",
    "    columns_fill.extend(selected_columns)\n",
    "    \n",
    "    return columns_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a616fd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:42:29.183649Z",
     "iopub.status.busy": "2024-01-30T22:42:29.183401Z",
     "iopub.status.idle": "2024-01-30T22:42:29.189553Z",
     "shell.execute_reply": "2024-01-30T22:42:29.188742Z"
    },
    "papermill": {
     "duration": 0.01874,
     "end_time": "2024-01-30T22:42:29.191492",
     "exception": false,
     "start_time": "2024-01-30T22:42:29.172752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sun_hours_df():\n",
    "    start_date = datetime(2020, 1, 1)\n",
    "    end_date = datetime(2026, 12, 31)\n",
    "    date_range = pd.date_range(start_date, end_date, freq='D')\n",
    "    df_sun_hours = pd.DataFrame({'date': date_range})\n",
    "    df_sun_hours['date'] = pd.to_datetime(df_sun_hours['date'])\n",
    "    \n",
    "    df_sun_hours['year'] = df_sun_hours['date'].dt.year\n",
    "    df_sun_hours['month'] = df_sun_hours['date'].dt.month\n",
    "    df_sun_hours['day'] = df_sun_hours['date'].dt.day\n",
    "\n",
    "    df_sun_hours['sunrise'], df_sun_hours['sunset'] = zip(*df_sun_hours['date'].apply(calculate_sunrise_sunset))\n",
    "\n",
    "    df_sun_hours.drop(columns = ['date'], inplace = True)\n",
    "\n",
    "    return df_sun_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca2360da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:42:29.212595Z",
     "iopub.status.busy": "2024-01-30T22:42:29.212349Z",
     "iopub.status.idle": "2024-01-30T22:42:29.218558Z",
     "shell.execute_reply": "2024-01-30T22:42:29.217753Z"
    },
    "papermill": {
     "duration": 0.018858,
     "end_time": "2024-01-30T22:42:29.220432",
     "exception": false,
     "start_time": "2024-01-30T22:42:29.201574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_sunrise_sunset(date):\n",
    "    observer = ephem.Observer()\n",
    "    observer.lat = '59.4370'  # Latitude for Tallinn, Estonia\n",
    "    observer.lon = '24.7536'  # Longitude for Tallinn, Estonia\n",
    "    observer.date = date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # get sunrise and set based on the location and date\n",
    "    sunrise = observer.next_rising(ephem.Sun()).datetime()\n",
    "    sunset = observer.next_setting(ephem.Sun()).datetime()\n",
    "    \n",
    "    # converts UTC to EET/EEST\n",
    "    tallinn_timezone = pytz.timezone('Europe/Tallinn')\n",
    "    sunrise_local = sunrise.replace(tzinfo=pytz.utc).astimezone(tallinn_timezone).replace(tzinfo=None)\n",
    "    sunset_local = sunset.replace(tzinfo=pytz.utc).astimezone(tallinn_timezone).replace(tzinfo=None)\n",
    "    \n",
    "    return sunrise_local, sunset_local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6870d2",
   "metadata": {
    "papermill": {
     "duration": 0.009873,
     "end_time": "2024-01-30T22:42:29.240425",
     "exception": false,
     "start_time": "2024-01-30T22:42:29.230552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4168c117",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:42:29.261574Z",
     "iopub.status.busy": "2024-01-30T22:42:29.261297Z",
     "iopub.status.idle": "2024-01-30T22:42:29.266829Z",
     "shell.execute_reply": "2024-01-30T22:42:29.266021Z"
    },
    "papermill": {
     "duration": 0.018222,
     "end_time": "2024-01-30T22:42:29.268687",
     "exception": false,
     "start_time": "2024-01-30T22:42:29.250465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_moving_avg_target(df_target, windows_ma_days = [15,30]):\n",
    "    windows_ma_target = [x * 24 for x in windows_ma_days]\n",
    "    \n",
    "    df_target_ma = df_target.clone()\n",
    "\n",
    "    for window in windows_ma_target:\n",
    "        df_target_ma = df_target_ma.with_columns(\n",
    "            rolling_mean=pl.col(\"target\").rolling_mean(window_size=window).over(['county', 'is_business', 'product_type', 'is_consumption']),\n",
    "        )\n",
    "    \n",
    "        df_target_ma = df_target_ma.rename({\"rolling_mean\": f'rolling_mean_{int(window/24)}'})\n",
    "        \n",
    "    return df_target_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3119bb71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:42:29.290406Z",
     "iopub.status.busy": "2024-01-30T22:42:29.290161Z",
     "iopub.status.idle": "2024-01-30T22:42:29.328852Z",
     "shell.execute_reply": "2024-01-30T22:42:29.328220Z"
    },
    "papermill": {
     "duration": 0.051744,
     "end_time": "2024-01-30T22:42:29.330728",
     "exception": false,
     "start_time": "2024-01-30T22:42:29.278984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_features(\n",
    "        df_data, \n",
    "        df_client, \n",
    "        df_gas_prices, \n",
    "        df_electricity_prices, \n",
    "        df_forecast_weather, \n",
    "        df_historical_weather, \n",
    "        df_weather_station_to_county_mapping, \n",
    "        df_target,\n",
    "        df_target_ma\n",
    "):\n",
    "    df_data = (\n",
    "        df_data\n",
    "        .with_columns(\n",
    "            pl.col(\"datetime\").cast(pl.Date).alias(\"date\"),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    df_gas_prices = (\n",
    "        df_gas_prices\n",
    "        .rename({\"forecast_date\": \"date\"})\n",
    "    )\n",
    "    \n",
    "    df_electricity_prices = (\n",
    "        df_electricity_prices\n",
    "        .rename({\"forecast_date\": \"datetime\"})\n",
    "    )\n",
    "    \n",
    "    df_weather_station_to_county_mapping = (\n",
    "        df_weather_station_to_county_mapping\n",
    "        .with_columns(\n",
    "            pl.col(\"latitude\").cast(pl.datatypes.Float32),\n",
    "            pl.col(\"longitude\").cast(pl.datatypes.Float32)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # sum of all product_type targets related to [\"datetime\", \"county\", \"is_business\", \"is_consumption\"]\n",
    "    df_target_all_type_sum = (\n",
    "        df_target\n",
    "        .group_by([\"datetime\", \"county\", \"is_business\", \"is_consumption\"]).sum()\n",
    "        .drop(\"product_type\")\n",
    "    )\n",
    "    \n",
    "    df_forecast_weather = (\n",
    "        df_forecast_weather\n",
    "        .rename({\"forecast_datetime\": \"datetime\"})\n",
    "        .filter(pl.col(\"hours_ahead\") >= 24) # we don't need forecast for today\n",
    "        .with_columns(\n",
    "            pl.col(\"latitude\").cast(pl.datatypes.Float32),\n",
    "            pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "            # datetime for forecast in a different timezone\n",
    "            pl.col('datetime').dt.replace_time_zone(None).cast(pl.Datetime(\"us\"))\n",
    "        )\n",
    "        .join(df_weather_station_to_county_mapping, how=\"left\", on=[\"longitude\", \"latitude\"])\n",
    "        .drop(\"longitude\", \"latitude\")\n",
    "    )\n",
    "    \n",
    "    df_historical_weather = (\n",
    "        df_historical_weather\n",
    "        .with_columns(\n",
    "            pl.col(\"latitude\").cast(pl.datatypes.Float32),\n",
    "            pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "#            pl.col(\"datetime\") + pl.duration(hours=37)\n",
    "        )\n",
    "        .join(df_weather_station_to_county_mapping, how=\"left\", on=[\"longitude\", \"latitude\"])\n",
    "        .drop(\"longitude\", \"latitude\")\n",
    "    )\n",
    "    \n",
    "    # creating average forecast characteristics for all weather stations\n",
    "    df_forecast_weather_date = (\n",
    "        df_forecast_weather\n",
    "        .group_by(\"datetime\").mean()\n",
    "        .drop(\"county\")\n",
    "    )\n",
    "    \n",
    "    # creating average forecast characteristics for weather stations related to county\n",
    "    df_forecast_weather_local = (\n",
    "        df_forecast_weather\n",
    "        .filter(pl.col(\"county\").is_not_null())\n",
    "        .group_by(\"county\", \"datetime\").mean()\n",
    "    )\n",
    "    \n",
    "    # creating average historical characteristics for all weather stations\n",
    "    df_historical_weather_date = (\n",
    "        df_historical_weather\n",
    "        .group_by(\"datetime\").mean()\n",
    "        .drop(\"county\")\n",
    "    )\n",
    "    \n",
    "    # creating average historical characteristics for weather stations related to county\n",
    "    df_historical_weather_local = (\n",
    "        df_historical_weather\n",
    "        .filter(pl.col(\"county\").is_not_null())\n",
    "        .group_by(\"county\", \"datetime\").mean()\n",
    "    )\n",
    "    \n",
    "    df_data = (\n",
    "        df_data\n",
    "        # pl.duration(days=1) shifts datetime to join lag features (usually we join last available values)\n",
    "        .join(df_gas_prices.with_columns((pl.col(\"date\") + pl.duration(days=1)).cast(pl.Date)), on=\"date\", how=\"left\")\n",
    "        .join(df_client.with_columns((pl.col(\"date\") + pl.duration(days=2)).cast(pl.Date)), on=[\"county\", \"is_business\", \"product_type\", \"date\"], how=\"left\")\n",
    "        .join(df_electricity_prices.with_columns(pl.col(\"datetime\") + pl.duration(days=1)), on=\"datetime\", how=\"left\")\n",
    "        \n",
    "        # lag forecast_weather features (24 hours * days)\n",
    "        .join(df_forecast_weather_date, on=\"datetime\", how=\"left\", suffix=\"_fd\")\n",
    "        .join(df_forecast_weather_local, on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_fl\")\n",
    "        .join(df_forecast_weather_date.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=\"datetime\", how=\"left\", suffix=\"_fd_7d\")\n",
    "        .join(df_forecast_weather_local.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_fl_7d\")\n",
    "\n",
    "        # lag historical_weather features (24 hours * days)\n",
    "        .join(df_historical_weather_date.with_columns(pl.col(\"datetime\") + pl.duration(days=2)), on=\"datetime\", how=\"left\", suffix=\"_hd_2d\")\n",
    "        .join(df_historical_weather_local.with_columns(pl.col(\"datetime\") + pl.duration(days=2)), on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_hl_2d\")\n",
    "        .join(df_historical_weather_date.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=\"datetime\", how=\"left\", suffix=\"_hd_7d\")\n",
    "        .join(df_historical_weather_local.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_hl_7d\")\n",
    "        \n",
    "        # lag target features (24 hours * days)\n",
    "        .join(df_target_ma.with_columns(pl.col(\"datetime\") + pl.duration(days=2)).rename({\"target\": \"target_2\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=3)).rename({\"target\": \"target_3\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=4)).rename({\"target\": \"target_4\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=5)).rename({\"target\": \"target_5\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=6)).rename({\"target\": \"target_6\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=7)).rename({\"target\": \"target_7\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=8)).rename({\"target\": \"target_8\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=9)).rename({\"target\": \"target_9\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=10)).rename({\"target\": \"target_10\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=11)).rename({\"target\": \"target_11\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=12)).rename({\"target\": \"target_12\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=13)).rename({\"target\": \"target_13\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=14)).rename({\"target\": \"target_14\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        \n",
    "        .join(df_target_all_type_sum.with_columns(pl.col(\"datetime\") + pl.duration(days=2)).rename({\"target\": \"target_1\"}), on=[\"county\", \"is_business\", \"is_consumption\", \"datetime\"], suffix=\"_all_type_sum\", how=\"left\")\n",
    "        .join(df_target_all_type_sum.with_columns(pl.col(\"datetime\") + pl.duration(days=3)).rename({\"target\": \"target_2\"}), on=[\"county\", \"is_business\", \"is_consumption\", \"datetime\"], suffix=\"_all_type_sum\", how=\"left\")\n",
    "        .join(df_target_all_type_sum.with_columns(pl.col(\"datetime\") + pl.duration(days=7)).rename({\"target\": \"target_6\"}), on=[\"county\", \"is_business\", \"is_consumption\", \"datetime\"], suffix=\"_all_type_sum\", how=\"left\")\n",
    "        .join(df_target_all_type_sum.with_columns(pl.col(\"datetime\") + pl.duration(days=14)).rename({\"target\": \"target_7\"}), on=[\"county\", \"is_business\", \"is_consumption\", \"datetime\"], suffix=\"_all_type_sum\", how=\"left\")\n",
    "        \n",
    "        \n",
    "        .with_columns(\n",
    "            pl.col(\"datetime\").dt.ordinal_day().alias(\"dayofyear\"),\n",
    "            pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n",
    "            pl.col(\"datetime\").dt.day().alias(\"day\"),\n",
    "            pl.col(\"datetime\").dt.weekday().alias(\"weekday\"),\n",
    "            pl.col(\"datetime\").dt.month().alias(\"month\"),\n",
    "            pl.col(\"datetime\").dt.year().alias(\"year\"),\n",
    "        )\n",
    "        \n",
    "        .with_columns(\n",
    "            pl.concat_str(\"county\", \"is_business\", \"product_type\", \"is_consumption\", separator=\"_\").alias(\"segment\"),\n",
    "        )\n",
    "        \n",
    "        # cyclical features encoding https://towardsdatascience.com/cyclical-features-encoding-its-about-time-ce23581845ca\n",
    "        .with_columns(\n",
    "            (np.pi * pl.col(\"dayofyear\") / 183).sin().alias(\"sin(dayofyear)\"),\n",
    "            (np.pi * pl.col(\"dayofyear\") / 183).cos().alias(\"cos(dayofyear)\"),\n",
    "            (np.pi * pl.col(\"hour\") / 12).sin().alias(\"sin(hour)\"),\n",
    "            (np.pi * pl.col(\"hour\") / 12).cos().alias(\"cos(hour)\"),\n",
    "        )\n",
    "        \n",
    "        .with_columns(\n",
    "            pl.col(pl.Float64).cast(pl.Float32),\n",
    "        )\n",
    "        \n",
    "        .drop(\"date\", \"hour\", \"dayofyear\")\n",
    "    )\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46674def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:42:29.351782Z",
     "iopub.status.busy": "2024-01-30T22:42:29.351533Z",
     "iopub.status.idle": "2024-01-30T22:42:29.359121Z",
     "shell.execute_reply": "2024-01-30T22:42:29.358313Z"
    },
    "papermill": {
     "duration": 0.020188,
     "end_time": "2024-01-30T22:42:29.361010",
     "exception": false,
     "start_time": "2024-01-30T22:42:29.340822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_pandas(X, y = None):\n",
    "    cat_cols = [\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"segment\"]\n",
    "    \n",
    "    if y is not None:\n",
    "        df = pd.concat([X.to_pandas(), y.to_pandas()], axis=1)\n",
    "    else:\n",
    "        df = X.to_pandas()    \n",
    "    \n",
    "    df = df.set_index(\"row_id\")\n",
    "    df[cat_cols] = df[cat_cols].astype(\"category\")\n",
    "    \n",
    "    df[\"target_mean_1\"] = df[[f\"target_{i}\" for i in range(2,8)]].mean(1)\n",
    "    df[\"target_mean_2\"] = df[[f\"target_{i}\" for i in range(2,15)]].mean(1)\n",
    "    df[\"target_std_1\"] = df[[f\"target_{i}\" for i in range(2, 8)]].std(1)\n",
    "    df[\"target_std_2\"] = df[[f\"target_{i}\" for i in range(2, 15)]].std(1)\n",
    "    df[\"target_ratio_1\"] = df[\"target_2\"] / (df[\"target_7\"] + 1e-3)\n",
    "    df[\"target_ratio_2\"] = df[\"target_7\"] / (df[\"target_14\"] + 1e-3)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5390bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:42:29.382241Z",
     "iopub.status.busy": "2024-01-30T22:42:29.381601Z",
     "iopub.status.idle": "2024-01-30T22:42:29.390683Z",
     "shell.execute_reply": "2024-01-30T22:42:29.390053Z"
    },
    "papermill": {
     "duration": 0.021549,
     "end_time": "2024-01-30T22:42:29.392563",
     "exception": false,
     "start_time": "2024-01-30T22:42:29.371014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deal_null(df):\n",
    "    # these will be filled be the mean of the county\n",
    "    columns_fill = ['eic_count', 'installed_capacity', 'target_2','target_3','target_4','target_5', 'target_6','target_7','target_8',\n",
    "                    'target_9','target_10','target_11','target_12','target_13','target_14','target_mean_1','target_std_1','target_mean_2','target_std_2',\n",
    "                    'target_ratio_1','target_ratio_2',  'lowest_price_per_mwh', 'highest_price_per_mwh', 'euros_per_mwh']\n",
    "\n",
    "    for column in columns_fill:\n",
    "        df[column] = df.groupby(['county', 'is_business', 'product_type', 'is_consumption'])[column].fillna(method='ffill')\n",
    "        df[column] = df.groupby(['county', 'is_business', 'product_type', 'is_consumption'])[column].fillna(method='bfill')\n",
    "    \n",
    "    \n",
    "    # these will be filled be the mean of the datetime\n",
    "    columns_fill = ['euros_per_mwh']\n",
    "    columns_fill = extend_columns_fill(columns_fill, df)\n",
    "\n",
    "    mean_values = df.groupby('datetime')[columns_fill].transform('mean')\n",
    "    df = pd.concat([df, mean_values.add_suffix('_mean')], axis=1)\n",
    "    \n",
    "    for column in columns_fill:\n",
    "        df[column] = df[column].fillna(df[column + '_mean'])\n",
    "        \n",
    "    df.drop(columns=[col + '_mean' for col in columns_fill], inplace=True, axis=1)\n",
    "    \n",
    "    #ffill with the ones still null\n",
    "    for column in columns_fill:\n",
    "        df[column] = df.groupby(['county', 'is_business', 'product_type', 'is_consumption'])[column].fillna(method='ffill')\n",
    "        \n",
    "    df.drop(columns = ['hours_ahead_fl', 'hours_ahead_fl_7d', 'hours_ahead_fd_7d'], inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b484fd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:42:29.413391Z",
     "iopub.status.busy": "2024-01-30T22:42:29.413155Z",
     "iopub.status.idle": "2024-01-30T22:42:29.419622Z",
     "shell.execute_reply": "2024-01-30T22:42:29.418855Z"
    },
    "papermill": {
     "duration": 0.018972,
     "end_time": "2024-01-30T22:42:29.421528",
     "exception": false,
     "start_time": "2024-01-30T22:42:29.402556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_holiday_day_night(df):\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df.loc[:,'date'] = df['datetime'].dt.date\n",
    "    \n",
    "    #holiday\n",
    "    df = df.merge(df_estonian_holidays, on = ['date'], how = 'left', indicator = 'is_holiday')\n",
    "    df.replace({'left_only': 0, 'both': 1, 'right_only': None}, inplace = True)\n",
    "    \n",
    "    # day/night\n",
    "    df_sun_hours = create_sun_hours_df()\n",
    "    df = df.merge(df_sun_hours, on = ['year', 'month', 'day'], how = 'left')\n",
    "    df.loc[:,'is_night'] = np.where((df['datetime'] >= df['sunrise']) \n",
    "                            & (df['datetime'] <= df['sunset']), 0, 1)\n",
    "    \n",
    "    df.drop(columns = ['date', 'sunrise', 'sunset'], inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14b95c6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:42:29.442400Z",
     "iopub.status.busy": "2024-01-30T22:42:29.442120Z",
     "iopub.status.idle": "2024-01-30T22:42:29.446471Z",
     "shell.execute_reply": "2024-01-30T22:42:29.445707Z"
    },
    "papermill": {
     "duration": 0.016781,
     "end_time": "2024-01-30T22:42:29.448295",
     "exception": false,
     "start_time": "2024-01-30T22:42:29.431514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_dtypes(df):\n",
    "    columns_change = ['county', 'is_business', 'product_type', 'is_consumption', 'is_holiday']\n",
    "    \n",
    "    for column in columns_change:\n",
    "        df[column] = df[column].astype('int32')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ea35ecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:42:29.469187Z",
     "iopub.status.busy": "2024-01-30T22:42:29.468946Z",
     "iopub.status.idle": "2024-01-30T22:42:29.475660Z",
     "shell.execute_reply": "2024-01-30T22:42:29.474941Z"
    },
    "papermill": {
     "duration": 0.019249,
     "end_time": "2024-01-30T22:42:29.477514",
     "exception": false,
     "start_time": "2024-01-30T22:42:29.458265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_moving_avg_weather(df, window_sizes_avg = [8], window_sizes_std = [5]):\n",
    "    columns_groupby = ['county', 'is_business', 'product_type', 'is_consumption']\n",
    "    columns_ma = ['temperature', 'dewpoint','cloudcover_high','cloudcover_low','cloudcover_mid','cloudcover_total',\n",
    "              '10_metre_u_wind_component','10_metre_v_wind_component','direct_solar_radiation',\n",
    "              'surface_solar_radiation_downwards','snowfall','total_precipitation']\n",
    "    \n",
    "    for window_size in window_sizes_avg:\n",
    "        for column in columns_ma:\n",
    "            df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
    "            \n",
    "    for window_size in window_sizes_std:\n",
    "        for column in columns_ma:\n",
    "            df[column + '_STD_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).std())\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4e1904b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:42:29.498504Z",
     "iopub.status.busy": "2024-01-30T22:42:29.498247Z",
     "iopub.status.idle": "2024-01-30T22:44:14.918923Z",
     "shell.execute_reply": "2024-01-30T22:44:14.917690Z"
    },
    "papermill": {
     "duration": 105.4341,
     "end_time": "2024-01-30T22:44:14.921494",
     "exception": false,
     "start_time": "2024-01-30T22:42:29.487394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26/75674610.py:8: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column] = df.groupby(['county', 'is_business', 'product_type', 'is_consumption'])[column].fillna(method='ffill')\n",
      "/tmp/ipykernel_26/75674610.py:8: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column] = df.groupby(['county', 'is_business', 'product_type', 'is_consumption'])[column].fillna(method='ffill')\n",
      "/tmp/ipykernel_26/75674610.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column] = df.groupby(['county', 'is_business', 'product_type', 'is_consumption'])[column].fillna(method='bfill')\n",
      "/tmp/ipykernel_26/75674610.py:9: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column] = df.groupby(['county', 'is_business', 'product_type', 'is_consumption'])[column].fillna(method='bfill')\n",
      "/tmp/ipykernel_26/75674610.py:26: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column] = df.groupby(['county', 'is_business', 'product_type', 'is_consumption'])[column].fillna(method='ffill')\n",
      "/tmp/ipykernel_26/75674610.py:26: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column] = df.groupby(['county', 'is_business', 'product_type', 'is_consumption'])[column].fillna(method='ffill')\n",
      "/tmp/ipykernel_26/2516656167.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.loc[:,'date'] = df['datetime'].dt.date\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_MA_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
      "/tmp/ipykernel_26/3115524238.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_STD_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).std())\n",
      "/tmp/ipykernel_26/3115524238.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_STD_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).std())\n",
      "/tmp/ipykernel_26/3115524238.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_STD_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).std())\n",
      "/tmp/ipykernel_26/3115524238.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_STD_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).std())\n",
      "/tmp/ipykernel_26/3115524238.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_STD_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).std())\n",
      "/tmp/ipykernel_26/3115524238.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_STD_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).std())\n",
      "/tmp/ipykernel_26/3115524238.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_STD_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).std())\n",
      "/tmp/ipykernel_26/3115524238.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_STD_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).std())\n",
      "/tmp/ipykernel_26/3115524238.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_STD_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).std())\n",
      "/tmp/ipykernel_26/3115524238.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_STD_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).std())\n",
      "/tmp/ipykernel_26/3115524238.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_STD_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).std())\n",
      "/tmp/ipykernel_26/3115524238.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[column + '_STD_' + str(window_size) + 'hours'] = df.groupby(columns_groupby)[column].transform(lambda x: x.rolling(window=window_size, min_periods=1).std())\n"
     ]
    }
   ],
   "source": [
    "df_data, y = df_data.drop(\"target\"), df_data.select(\"target\")\n",
    "\n",
    "windows_ma_days = [15,30]\n",
    "df_target_ma = create_moving_avg_target(df_target, windows_ma_days)\n",
    "\n",
    "df_train_features = generate_features(\n",
    "    df_data, \n",
    "    df_client, \n",
    "    df_gas_prices, \n",
    "    df_electricity_prices, \n",
    "    df_forecast_weather, \n",
    "    df_historical_weather, \n",
    "    df_weather_station_to_county_mapping, \n",
    "    df_target,\n",
    "    df_target_ma\n",
    ")\n",
    "\n",
    "df_train_features = to_pandas(df_train_features, y)\n",
    "\n",
    "# a little proportion of target values are null\n",
    "df_train_features = df_train_features[df_train_features['target'].notnull()]\n",
    "\n",
    "# filter old data\n",
    "df_train_features = df_train_features[df_train_features.year >= 2022]\n",
    "\n",
    "# deal with null values\n",
    "df_train_features = deal_null(df_train_features)\n",
    "\n",
    "# get holidays and day/night features\n",
    "df_train_features = get_holiday_day_night(df_train_features)\n",
    "\n",
    "window_sizes_avg = [8, 12]\n",
    "window_sizes_std = [5]\n",
    "df_train_features = create_moving_avg_weather(df_train_features, window_sizes_avg, window_sizes_std)\n",
    "\n",
    "df_train_features.drop(columns = ['datetime', 'segment'], inplace = True)\n",
    "\n",
    "df_train_features = convert_dtypes(df_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11da6e9",
   "metadata": {
    "papermill": {
     "duration": 0.013246,
     "end_time": "2024-01-30T22:44:14.948519",
     "exception": false,
     "start_time": "2024-01-30T22:44:14.935273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "146fa652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:44:14.977192Z",
     "iopub.status.busy": "2024-01-30T22:44:14.976474Z",
     "iopub.status.idle": "2024-01-30T22:44:14.983372Z",
     "shell.execute_reply": "2024-01-30T22:44:14.982509Z"
    },
    "papermill": {
     "duration": 0.02333,
     "end_time": "2024-01-30T22:44:14.985335",
     "exception": false,
     "start_time": "2024-01-30T22:44:14.962005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MonthlyKFold:\n",
    "    def __init__(self, n_splits=3):\n",
    "        self.n_splits = n_splits\n",
    "        \n",
    "    def split(self, X, y, groups=None):\n",
    "        dates = 12 * X[\"year\"] + X[\"month\"]\n",
    "        timesteps = sorted(dates.unique().tolist())\n",
    "        X = X.reset_index()\n",
    "        \n",
    "        for t in timesteps[-self.n_splits:]:\n",
    "            idx_train = X[dates.values < t].index\n",
    "            idx_test = X[dates.values == t].index\n",
    "            \n",
    "            yield idx_train, idx_test\n",
    "            \n",
    "    def get_n_splits(self, X, y, groups=None):\n",
    "        return self.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "134c277b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:44:15.060912Z",
     "iopub.status.busy": "2024-01-30T22:44:15.060169Z",
     "iopub.status.idle": "2024-01-30T22:44:15.064775Z",
     "shell.execute_reply": "2024-01-30T22:44:15.063954Z"
    },
    "papermill": {
     "duration": 0.022468,
     "end_time": "2024-01-30T22:44:15.067058",
     "exception": false,
     "start_time": "2024-01-30T22:44:15.044590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = df_train_features.columns.tolist()\n",
    "features.remove('target')\n",
    "features.remove('is_consumption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61f3ae73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:44:15.097505Z",
     "iopub.status.busy": "2024-01-30T22:44:15.097253Z",
     "iopub.status.idle": "2024-01-30T22:44:18.609687Z",
     "shell.execute_reply": "2024-01-30T22:44:18.608665Z"
    },
    "papermill": {
     "duration": 3.529925,
     "end_time": "2024-01-30T22:44:18.612181",
     "exception": false,
     "start_time": "2024-01-30T22:44:15.082256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_0 = df_train_features[df_train_features['is_consumption'] == 0][features]\n",
    "y_0 = df_train_features[df_train_features['is_consumption'] == 0]['target']\n",
    "X_1 = df_train_features[df_train_features['is_consumption'] == 1][features]\n",
    "y_1 = df_train_features[df_train_features['is_consumption'] == 1]['target']\n",
    "\n",
    "y_diff_0 = df_train_features[df_train_features['is_consumption'] == 0]['target'] - df_train_features[df_train_features['is_consumption'] == 0]['target_2'].fillna(0)\n",
    "y_diff_1 = df_train_features[df_train_features['is_consumption'] == 1]['target'] - df_train_features[df_train_features['is_consumption'] == 1]['target_2'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b2d6d",
   "metadata": {
    "papermill": {
     "duration": 0.013237,
     "end_time": "2024-01-30T22:44:18.639221",
     "exception": false,
     "start_time": "2024-01-30T22:44:18.625984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23300c03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:44:18.667217Z",
     "iopub.status.busy": "2024-01-30T22:44:18.666910Z",
     "iopub.status.idle": "2024-01-30T22:44:18.671121Z",
     "shell.execute_reply": "2024-01-30T22:44:18.670271Z"
    },
    "papermill": {
     "duration": 0.020427,
     "end_time": "2024-01-30T22:44:18.672977",
     "exception": false,
     "start_time": "2024-01-30T22:44:18.652550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'reg_alpha':5, \n",
    "#     'reg_lambda':3.5, \n",
    "#     'n_estimators':3000, \n",
    "#     'num_leaves':500, \n",
    "#     'learning_rate' : 0.05, \n",
    "#     'max_depth' : 12,\n",
    "#     'objective' : \"regression_l1\", \n",
    "#     'colsample_bytree' : 0.8, \n",
    "#     'colsample_bynode' : 0.7   \n",
    "# }\n",
    "\n",
    "# model_0 = lgb.LGBMRegressor(**params)\n",
    "# model_1 = lgb.LGBMRegressor(**params)\n",
    "# model_0_diff = lgb.LGBMRegressor(**params)\n",
    "# model_1_diff = lgb.LGBMRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d97ee09d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:44:18.700485Z",
     "iopub.status.busy": "2024-01-30T22:44:18.700229Z",
     "iopub.status.idle": "2024-01-30T22:44:18.704041Z",
     "shell.execute_reply": "2024-01-30T22:44:18.703186Z"
    },
    "papermill": {
     "duration": 0.019689,
     "end_time": "2024-01-30T22:44:18.705848",
     "exception": false,
     "start_time": "2024-01-30T22:44:18.686159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cv = MonthlyKFold(1)\n",
    "\n",
    "# scores_0 = cross_val_score(model_0, X_0, y_0, cv=cv, scoring='neg_mean_absolute_error')\n",
    "# scores_1 = cross_val_score(model_1, X_1, y_1, cv=cv, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25109ef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:44:18.733320Z",
     "iopub.status.busy": "2024-01-30T22:44:18.733075Z",
     "iopub.status.idle": "2024-01-30T22:44:18.736674Z",
     "shell.execute_reply": "2024-01-30T22:44:18.735843Z"
    },
    "papermill": {
     "duration": 0.01951,
     "end_time": "2024-01-30T22:44:18.738665",
     "exception": false,
     "start_time": "2024-01-30T22:44:18.719155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(scores_0)\n",
    "# #print(scores_0.mean())\n",
    "\n",
    "# print(scores_1)\n",
    "# #print(scores_1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b13d4d5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:44:18.766363Z",
     "iopub.status.busy": "2024-01-30T22:44:18.766030Z",
     "iopub.status.idle": "2024-01-30T22:44:18.770059Z",
     "shell.execute_reply": "2024-01-30T22:44:18.769168Z"
    },
    "papermill": {
     "duration": 0.02006,
     "end_time": "2024-01-30T22:44:18.771943",
     "exception": false,
     "start_time": "2024-01-30T22:44:18.751883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# params_cat = {\n",
    "#     'iterations':2000,\n",
    "#     'depth':12, \n",
    "#     'learning_rate':0.05, \n",
    "#     'loss_function':'RMSE', \n",
    "#     'l2_leaf_reg': 3, \n",
    "#     'verbose': False\n",
    "# }\n",
    "\n",
    "# cat_model_0 = CatBoostRegressor(**params_cat)\n",
    "# cat_model_1 = CatBoostRegressor(**params_cat)\n",
    "\n",
    "# scores_0 = cross_val_score(cat_model_0, X_0, y_0, cv=cv, scoring='neg_mean_absolute_error')\n",
    "# scores_1 = cross_val_score(cat_model_1, X_1, y_1, cv=cv, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca6724d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:44:18.799338Z",
     "iopub.status.busy": "2024-01-30T22:44:18.799072Z",
     "iopub.status.idle": "2024-01-30T22:44:18.802523Z",
     "shell.execute_reply": "2024-01-30T22:44:18.801793Z"
    },
    "papermill": {
     "duration": 0.019167,
     "end_time": "2024-01-30T22:44:18.804401",
     "exception": false,
     "start_time": "2024-01-30T22:44:18.785234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(scores_0)\n",
    "# print(scores_0.mean())\n",
    "\n",
    "# print(scores_1)\n",
    "# print(scores_1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15513332",
   "metadata": {
    "papermill": {
     "duration": 0.01306,
     "end_time": "2024-01-30T22:44:18.830619",
     "exception": false,
     "start_time": "2024-01-30T22:44:18.817559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Votting Regressor + Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33ba0f6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:44:18.857871Z",
     "iopub.status.busy": "2024-01-30T22:44:18.857576Z",
     "iopub.status.idle": "2024-01-30T22:44:18.868506Z",
     "shell.execute_reply": "2024-01-30T22:44:18.867684Z"
    },
    "papermill": {
     "duration": 0.026518,
     "end_time": "2024-01-30T22:44:18.870359",
     "exception": false,
     "start_time": "2024-01-30T22:44:18.843841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_states = [10, 20, 30, 40, 50]\n",
    "\n",
    "lgbm_models_0 = [lgb.LGBMRegressor(reg_alpha=5, reg_lambda=4, n_estimators=3000, num_leaves=500, learning_rate = 0.04, max_depth = 12,objective = \"regression_l1\", colsample_bytree = 0.85, colsample_bynode = 0.7, device = 'gpu',random_state=rs) for rs in random_states]\n",
    "lgbm_models_1 = [lgb.LGBMRegressor(reg_alpha=5, reg_lambda=4, n_estimators=3000, num_leaves=500, learning_rate = 0.04, max_depth = 12,objective = \"regression_l1\", colsample_bytree = 0.85, colsample_bynode = 0.7, device = 'gpu',random_state=rs) for rs in random_states]\n",
    "lgbm_models_0_dif = [lgb.LGBMRegressor(reg_alpha=5, reg_lambda=4, n_estimators=3000, num_leaves=500, learning_rate = 0.04, max_depth = 12, objective = \"regression_l1\", colsample_bytree = 0.85, colsample_bynode = 0.7, device = 'gpu',random_state=rs) for rs in random_states]\n",
    "lgbm_models_1_dif = [lgb.LGBMRegressor(reg_alpha=5, reg_lambda=4, n_estimators=3000, num_leaves=500, learning_rate = 0.04, max_depth = 12, objective = \"regression_l1\", colsample_bytree = 0.85, colsample_bynode = 0.7, device = 'gpu',random_state=rs) for rs in random_states]\n",
    "\n",
    "model_0 = VotingRegressor(estimators=[('lgbm_' + str(rs), model) for rs, model in zip(random_states, lgbm_models_0)])\n",
    "model_1 = VotingRegressor(estimators=[('lgbm_' + str(rs), model) for rs, model in zip(random_states, lgbm_models_1)])\n",
    "model_0_diff = VotingRegressor(estimators=[('lgbm_' + str(rs), model) for rs, model in zip(random_states, lgbm_models_0_dif)])\n",
    "model_1_diff = VotingRegressor(estimators=[('lgbm_' + str(rs), model) for rs, model in zip(random_states, lgbm_models_1_dif)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5be7b373",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:44:18.897721Z",
     "iopub.status.busy": "2024-01-30T22:44:18.897444Z",
     "iopub.status.idle": "2024-01-30T22:44:18.905617Z",
     "shell.execute_reply": "2024-01-30T22:44:18.904862Z"
    },
    "papermill": {
     "duration": 0.023929,
     "end_time": "2024-01-30T22:44:18.907455",
     "exception": false,
     "start_time": "2024-01-30T22:44:18.883526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_cat = {\n",
    "    'iterations':2500,\n",
    "    'depth':12, \n",
    "    'learning_rate':0.04, \n",
    "    'loss_function':'RMSE', \n",
    "    'l2_leaf_reg': 5, \n",
    "    'verbose': False,\n",
    "    'task_type':\"GPU\"\n",
    "}\n",
    "\n",
    "cat_model_0_base = CatBoostRegressor(**params_cat)\n",
    "cat_model_1_base = CatBoostRegressor(**params_cat)\n",
    "\n",
    "cat_model_0 = BaggingRegressor(cat_model_0_base, n_estimators=5, random_state=42)\n",
    "cat_model_1 = BaggingRegressor(cat_model_1_base, n_estimators=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba38120",
   "metadata": {
    "papermill": {
     "duration": 0.012892,
     "end_time": "2024-01-30T22:44:18.933921",
     "exception": false,
     "start_time": "2024-01-30T22:44:18.921029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "514ee26f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T22:44:18.961532Z",
     "iopub.status.busy": "2024-01-30T22:44:18.961255Z",
     "iopub.status.idle": "2024-01-31T02:44:23.211010Z",
     "shell.execute_reply": "2024-01-31T02:44:23.210140Z"
    },
    "papermill": {
     "duration": 14404.283569,
     "end_time": "2024-01-31T02:44:23.230768",
     "exception": false,
     "start_time": "2024-01-30T22:44:18.947199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingRegressor(estimator=&lt;catboost.core.CatBoostRegressor object at 0x7d28483525f0&gt;,\n",
       "                 n_estimators=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingRegressor</label><div class=\"sk-toggleable__content\"><pre>BaggingRegressor(estimator=&lt;catboost.core.CatBoostRegressor object at 0x7d28483525f0&gt;,\n",
       "                 n_estimators=5, random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: CatBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostRegressor object at 0x7d28483525f0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostRegressor object at 0x7d28483525f0&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingRegressor(estimator=<catboost.core.CatBoostRegressor object at 0x7d28483525f0>,\n",
       "                 n_estimators=5, random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.fit(X_0, y_0)\n",
    "model_1.fit(X_1, y_1)\n",
    "\n",
    "model_0_diff.fit(X_0, y_diff_0)\n",
    "model_1_diff.fit(X_1, y_diff_1)\n",
    "\n",
    "cat_model_0.fit(X_0, y_0)\n",
    "cat_model_1.fit(X_1, y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77dfddf",
   "metadata": {
    "papermill": {
     "duration": 0.016933,
     "end_time": "2024-01-31T02:44:23.264521",
     "exception": false,
     "start_time": "2024-01-31T02:44:23.247588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49205a8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T02:44:23.300574Z",
     "iopub.status.busy": "2024-01-31T02:44:23.299731Z",
     "iopub.status.idle": "2024-01-31T02:44:23.304532Z",
     "shell.execute_reply": "2024-01-31T02:44:23.303692Z"
    },
    "papermill": {
     "duration": 0.025612,
     "end_time": "2024-01-31T02:44:23.306747",
     "exception": false,
     "start_time": "2024-01-31T02:44:23.281135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature_importance0 = model_0.feature_importances_\n",
    "# feature_importance_df0 = pd.DataFrame({'Feature': features, 'Importance': feature_importance0})\n",
    "# feature_importance_df0 = feature_importance_df0.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# feature_importance1 = model_1.feature_importances_\n",
    "# feature_importance_df1 = pd.DataFrame({'Feature': features, 'Importance': feature_importance1})\n",
    "# feature_importance_df1 = feature_importance_df1.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# print(\"Feature Importance 0:\")\n",
    "# print(feature_importance_df0.head(50))\n",
    "\n",
    "# print(\"Feature Importance 1:\")\n",
    "# print(feature_importance_df1.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ce9fe",
   "metadata": {
    "papermill": {
     "duration": 0.016863,
     "end_time": "2024-01-31T02:44:23.340676",
     "exception": false,
     "start_time": "2024-01-31T02:44:23.323813",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4daee338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T02:44:23.375402Z",
     "iopub.status.busy": "2024-01-31T02:44:23.374509Z",
     "iopub.status.idle": "2024-01-31T02:44:23.400983Z",
     "shell.execute_reply": "2024-01-31T02:44:23.400160Z"
    },
    "papermill": {
     "duration": 0.046362,
     "end_time": "2024-01-31T02:44:23.403232",
     "exception": false,
     "start_time": "2024-01-31T02:44:23.356870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import enefit\n",
    "\n",
    "env = enefit.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2831d9",
   "metadata": {
    "papermill": {
     "duration": 0.016473,
     "end_time": "2024-01-31T02:44:23.436483",
     "exception": false,
     "start_time": "2024-01-31T02:44:23.420010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following code demonstrated usage of API when in each cycle step we simulate new day and we need to send prediciotns before we get the next day (this guranteeres that we don't see targets from future).\n",
    "\n",
    "Local running of a notebook uses toy example of test data, after notebook submission toy data will be replaced with new unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96adaaa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-31T02:44:23.471582Z",
     "iopub.status.busy": "2024-01-31T02:44:23.470754Z",
     "iopub.status.idle": "2024-01-31T02:44:23.789490Z",
     "shell.execute_reply": "2024-01-31T02:44:23.788633Z"
    },
    "papermill": {
     "duration": 0.339007,
     "end_time": "2024-01-31T02:44:23.792084",
     "exception": false,
     "start_time": "2024-01-31T02:44:23.453077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "for (\n",
    "    test, \n",
    "    revealed_targets, \n",
    "    client, \n",
    "    historical_weather,\n",
    "    forecast_weather, \n",
    "    electricity_prices, \n",
    "    gas_prices, \n",
    "    sample_prediction\n",
    ") in iter_test:\n",
    "    \n",
    "    if test.iloc[0]['currently_scored'] == False:\n",
    "        sample_prediction.loc[:]['target'] = 0\n",
    "        env.predict(sample_prediction)\n",
    "    else:\n",
    "        test = test.rename(columns={\"prediction_datetime\": \"datetime\"})\n",
    "\n",
    "        gas_prices.drop_duplicates(subset = ['forecast_date'], keep='first', inplace = True)\n",
    "        electricity_prices.drop_duplicates(subset = ['forecast_date'], keep='first', inplace = True)\n",
    "        client.drop_duplicates(subset = ['product_type', 'county', 'is_business', 'date'], keep='first', inplace = True)\n",
    "\n",
    "        df_test = pl.from_pandas(test[data_cols[1:]], schema_overrides=schema_data)\n",
    "        df_client = pl.from_pandas(client[client_cols], schema_overrides=schema_client)\n",
    "        df_gas_prices = pl.from_pandas(gas_prices[gas_prices_cols], schema_overrides=schema_gas)\n",
    "        df_electricity_prices = pl.from_pandas(electricity_prices[electricity_prices_cols], schema_overrides=schema_electricity)\n",
    "        df_new_forecast_weather = pl.from_pandas(forecast_weather[forecast_weather_cols], schema_overrides=schema_forecast)\n",
    "        df_new_historical_weather = pl.from_pandas(historical_weather[historical_weather_cols], schema_overrides=schema_historical)\n",
    "        df_new_target = pl.from_pandas(revealed_targets[target_cols], schema_overrides=schema_target)\n",
    "\n",
    "        df_forecast_weather = pl.concat([df_forecast_weather, df_new_forecast_weather]).unique(['forecast_datetime', 'latitude', 'longitude', 'hours_ahead'])\n",
    "        df_historical_weather = pl.concat([df_historical_weather, df_new_historical_weather]).unique(['datetime', 'latitude', 'longitude'])\n",
    "        df_target = pl.concat([df_target, df_new_target]).unique(['datetime', 'county', 'is_business', 'product_type', 'is_consumption'])\n",
    "\n",
    "        df_target_ma = create_moving_avg_target(df_target, windows_ma_days)\n",
    "\n",
    "        df_test_features = generate_features(\n",
    "            df_test, \n",
    "            df_client, \n",
    "            df_gas_prices, \n",
    "            df_electricity_prices, \n",
    "            df_forecast_weather, \n",
    "            df_historical_weather, \n",
    "            df_weather_station_to_county_mapping, \n",
    "            df_target,\n",
    "            df_target_ma\n",
    "        )\n",
    "\n",
    "        df_test_features = to_pandas(df_test_features)\n",
    "        df_test_features = deal_null(df_test_features)\n",
    "        df_test_features = get_holiday_day_night(df_test_features)\n",
    "        df_test_features = create_moving_avg_weather(df_test_features, window_sizes_avg, window_sizes_std)\n",
    "        df_test_features.drop(columns = ['datetime', 'segment'], inplace = True)\n",
    "        df_test_features = convert_dtypes(df_test_features)\n",
    "\n",
    "        predictions = np.zeros(len(sample_prediction))\n",
    "\n",
    "        mask = df_test_features['is_consumption'] != 1\n",
    "        predictions[mask.values] = 0.4*(model_0.predict(df_test_features.loc[mask,features].values)) + 0.4*(model_0_diff.predict(df_test_features.loc[mask,features].values) + df_test_features.loc[mask,'target_2'].fillna(0)) + 0.2*(cat_model_0.predict(df_test_features.loc[mask,features].values))\n",
    "        mask = df_test_features['is_consumption'] == 1\n",
    "        predictions[mask.values] =  0.4*(model_1.predict(df_test_features.loc[mask,features].values)) + 0.4*(model_1_diff.predict(df_test_features.loc[mask,features].values) + df_test_features.loc[mask,'target_2'].fillna(0)) + 0.2*(cat_model_1.predict(df_test_features.loc[mask,features].values))\n",
    "\n",
    "        sample_prediction['target'] = predictions\n",
    "\n",
    "        sample_prediction['target'] = sample_prediction['target'].clip(lower=0, upper = 15481)\n",
    "        sample_prediction = sample_prediction.replace([np.inf, -np.inf], np.nan)\n",
    "        sample_prediction['target'] = sample_prediction['target'].fillna(0)\n",
    "\n",
    "        sample_prediction['target'] = sample_prediction['target'].astype(float)\n",
    "        sample_prediction['row_id'] = sample_prediction['row_id'].astype(int)\n",
    "\n",
    "        sample_prediction = sample_prediction.groupby('row_id').agg({'target': np.mean}).reset_index()\n",
    "\n",
    "        env.predict(sample_prediction)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7292407,
     "sourceId": 57236,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14530.773001,
   "end_time": "2024-01-31T02:44:25.762367",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-30T22:42:14.989366",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
